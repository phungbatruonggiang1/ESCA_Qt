import sysv_ipc
import signal
import sys
import time
import numpy as np
from gammatone import gtgram
from tensorflow.keras.models import load_model
import os
import wave
import tensorflow as tf
try:
    from tensorflow.python.compiler.tensorrt import trt_convert as trt
except Exception:
    trt = None

from config.config_manager import ConfigManager

config_manager = ConfigManager()

# ƒê·ªãnh nghƒ©a kh√≥a v√† k√≠ch th∆∞·ªõc shared memory (ch·ªâ d√πng cho Real-time)
SHM_KEY = 0x1234
SEM_KEY = 0x5678
SHM_SIZE = 176400  # 2 gi√¢y d·ªØ li·ªáu = 176400 bytes = 88200 m·∫´u int16

EXCEED_LIMIT = 1

# L·∫•y tham s·ªë c·∫•u h√¨nh t·ª´ config
frame_rate = config_manager.get("PREPROCESS.FRAME_RATE")
window_time = config_manager.get("PREPROCESS.GAMMA.WINDOW_TIME")
hop_time = config_manager.get("PREPROCESS.GAMMA.HOP_TIME")
channels = config_manager.get("PREPROCESS.GAMMA.CHANNELS")
f_min = config_manager.get("PREPROCESS.GAMMA.F_MIN")
model_path = config_manager.get("REALTIME.MODEL_PATH") + "/saved_model/vq_vae"
manual_threshold = config_manager.get("REALTIME.MANUAL_THRESHOLD")
threshold = config_manager.get("REALTIME.THRESHOLD")
MIN = config_manager.get("REALTIME.MIN")
MAX = config_manager.get("REALTIME.MAX")

# print(f"model_path: {model_path}")
# print(f"frame_rate: {frame_rate}, window_time: {window_time}, hop_time: {hop_time}, channels: {channels}, f_min: {f_min}")
# print(f"manual_threshold: {manual_threshold}, threshold: {threshold}, MIN: {MIN}, MAX: {MAX}")

# Load model
use_trt = config_manager.get("DEVICE.USE_TENSORRT")
trt_model_path = config_manager.get("REALTIME.TRT_MODEL_PATH")

if use_trt and trt is not None:
    try:
        if trt_model_path and os.path.exists(trt_model_path):
            model = tf.saved_model.load(trt_model_path)
            infer = model.signatures['serving_default']
        else:
            converter = trt.TrtGraphConverterV2(input_saved_model_dir=model_path)
            converter.convert()
            if trt_model_path:
                converter.save(trt_model_path)
                model = tf.saved_model.load(trt_model_path)
            else:
                model = converter.convert()
            infer = model.signatures['serving_default'] if hasattr(model, 'signatures') else model
    except Exception as e:
        print(f"TensorRT conversion failed: {e}. Falling back to TensorFlow model.")
        model = load_model(model_path)
        infer = model
else:
    model = load_model(model_path)
    infer = model
# model.summary()

shm = None
semaphore = None

def cleanup():
    """D·ªçn d·∫πp shared memory v√† semaphore khi tho√°t."""
    global shm, semaphore
    if shm:
        try:
            shm.detach()
            print("Shared memory detached.")
        except Exception as e:
            print(f"Failed to detach shared memory: {e}")

def signal_handler(signum, frame):
    """X·ª≠ l√Ω t√≠n hi·ªáu (SIGINT, SIGTERM)."""
    print(f"Signal {signum} received. Exiting...")
    cleanup()
    sys.exit(0)

def wait_for_shared_memory():
    """Ch·ªù shared memory v√† semaphore c√≥ s·∫µn (ch·ªâ d√πng cho real-time)."""
    global shm, semaphore
    while True:
        try:
            shm = sysv_ipc.SharedMemory(SHM_KEY)
            print("Shared memory connected.")
            break
        except sysv_ipc.ExistentialError:
            print("Shared memory kh√¥ng t·ªìn t·∫°i. ƒêang ch·ªù...")
            time.sleep(1)

    while True:
        try:
            semaphore = sysv_ipc.Semaphore(SEM_KEY)
            print("Semaphore connected.")
            break
        except sysv_ipc.ExistentialError:
            print("Semaphore kh√¥ng t·ªìn t·∫°i. ƒêang ch·ªù...")
            time.sleep(1)

def predict_mse(audio_array):
    """D·ª± ƒëo√°n MSE t·ª´ audio array."""
    gtg = gtgram.gtgram(audio_array, frame_rate, window_time, hop_time, channels, f_min)
    a = np.flipud(20 * np.log10(gtg + 1e-10))  # Tr√°nh log(0)
    a = np.clip((a-MIN)/(MAX-MIN), a_min=0, a_max=1)
    # print(f"Spectrogram shape: {a.shape}")
    a = np.reshape(a, (1 ,a.shape[0], a.shape[1], 1))
    # print(f"Reshaped Spectrogram shape: {a.shape}")

    if a.shape != (1, 32, 32, 1):
        print(f"Input shape kh√¥ng h·ª£p l·ªá: {a.shape}")
        return None

    if use_trt and trt is not None and callable(infer):
        result = infer(tf.convert_to_tensor(a))
        if isinstance(result, dict):
            pred = list(result.values())[0].numpy()
        else:
            pred = result.numpy()
    else:
        pred = model.predict(a, verbose=0)
    return np.mean((a - pred) ** 2)  

def process_realtime():
    """X·ª≠ l√Ω Real-time: ƒê·ªçc shared memory v√† inference m·ªói 2 gi√¢y."""
    cycle_duration = 2.0  # ƒê·∫£m b·∫£o ƒë√∫ng chu k·ª≥ 2 gi√¢y
    last_read_time = time.time()

    while True:
        cycle_start = time.time()

        # ƒê·ª£i ƒë√∫ng chu k·ª≥ 2 gi√¢y k·ªÉ t·ª´ l·∫ßn ƒë·ªçc tr∆∞·ªõc
        if cycle_start - last_read_time < cycle_duration:
            time.sleep(cycle_duration - (cycle_start - last_read_time))
            continue

        last_read_time = cycle_start  # C·∫≠p nh·∫≠t th·ªùi ƒëi·ªÉm ƒë·ªçc m·ªõi nh·∫•t

        try:
            semaphore.acquire()
            raw_data = bytearray(shm.read(SHM_SIZE))
            semaphore.release()
        except sysv_ipc.BusyError:
            print("Semaphore is busy. Skipping this cycle.")
            continue

        if len(raw_data) != SHM_SIZE:
            print(f"‚ö†Ô∏è Warning: Expected {SHM_SIZE} bytes but got {len(raw_data)} bytes!")
            continue

        start_time = time.time()
        audio_array = np.frombuffer(raw_data, dtype=np.int16)
        # print(f"Real-time - Mean: {np.mean(audio_array)}, Std: {np.std(audio_array)}")
        # print(f"First 5 samples: {audio_array[:5]}")

        # print(f"Sample Rate: {sr}")
        # print(f"Audio Data Shape: {audio_array.shape}")
        # print(f"Max Value: {np.max(audio_array)}, Min Value: {np.min(audio_array)}")
        # print(f"Dtype: {audio_array.dtype}")
        # read_time = time.strftime('%H:%M:%S')
        # print(f"üîÑ Shared memory read at {read_time} - {len(audio_array)} samples, First 10 bit {audio_array[:30]}")

        mse = predict_mse(audio_array)
        if mse is None:
            continue

        # Ki·ªÉm tra anomaly
        if mse > manual_threshold:
            print("Anomaly detected!", flush=True)
        # print(f"Predict Result: {mse}", flush=True)
        print(mse, flush=True)

        # ƒê·∫£m b·∫£o ƒë·ªçc ƒë√∫ng m·ªói 2 gi√¢y
        elapsed = time.time() - cycle_start
        if elapsed < cycle_duration:
            time.sleep(cycle_duration - elapsed)

        end_time = time.time()
        print(f"Processing time: {end_time - start_time} seconds and Pred: {mse}")

def process_folder(folder_path):
    """
    X·ª≠ l√Ω √¢m thanh t·ª´ c√°c file WAV trong th∆∞ m·ª•c.
    """
    exceed_count = 0

    wav_files = [f for f in os.listdir(folder_path) if f.lower().endswith(".wav")]
    wav_files.sort()  # Sort to ensure order
    # print(f"Files: {wav_files}")

    for wav_file in wav_files:
        start_time = time.time()
        file_path = os.path.join(folder_path, wav_file)
        # print(f"\n=== ƒêang x·ª≠ l√Ω file: {file_path} ===")

        with wave.open(file_path, 'rb') as wav_file_obj:
            # L·∫•y th√¥ng tin file WAV
            num_channels = wav_file_obj.getnchannels()
            sample_width = wav_file_obj.getsampwidth()
            frame_rate = wav_file_obj.getframerate()
            num_frames = wav_file_obj.getnframes()

            # print(f"File: {wav_file}")
            # print(f"Sample Rate: {frame_rate}")
            # print(f"Channels: {num_channels}")
            # print(f"Sample Width: {sample_width}")
            # print(f"Num Frames: {num_frames}")        

            # ƒê·ªçc d·ªØ li·ªáu √¢m thanh t·ª´ file
            audio_data = wav_file_obj.readframes(num_frames)
            audio_array = np.frombuffer(audio_data, dtype=np.int16)

            # T√≠nh MSE
            mse = predict_mse(audio_array)
            if mse is None:
                continue

            # Ki·ªÉm tra anomaly
            if mse > manual_threshold:
                exceed_count += 1
            else:
                exceed_count = 0

            if exceed_count > EXCEED_LIMIT:
                print("Anomaly detected!", flush=True)
                exceed_count = 0  # reset
            print(mse, flush=True)

            end_time = time.time()
            print(f"Processing time for {wav_file}: {end_time - start_time} seconds and Pred: {mse}")

    print("Done Folder Mode")    

def main():
    """H√†m ch√≠nh: Ch·ªâ t·ªëi ∆∞u ph·∫ßn Real-time, gi·ªØ nguy√™n ch·∫ø ƒë·ªô ƒë·ªçc file t·ª´ folder."""
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    import_file = config_manager.get("REALTIME.IMPORT_FILE")  # True = Folder Mode, False = Real-time Mode
    print(f"IMPORT_FILE: {import_file}")

    if not import_file:
        # print("Ch·∫ø ƒë·ªô Real-time")
        wait_for_shared_memory()
        process_realtime()
    else:
        folder_path = config_manager.get("REALTIME.FOLDER_PATH")
        # print(f"Ch·∫ø ƒë·ªô Folder, x·ª≠ l√Ω th∆∞ m·ª•c: {folder_path}")
        process_folder(folder_path)  # Gi·ªØ nguy√™n kh√¥ng thay ƒë·ªïi

if __name__ == "__main__":
    main()