import sysv_ipc
import signal
import sys
import time
import numpy as np
from gammatone import gtgram
from tensorflow.keras.models import load_model

import tensorflow as tf
try:
    from tensorflow.python.compiler.tensorrt import trt_convert as trt
except Exception:
    trt = None

import os
import wave
import logging

from config.config_manager import ConfigManager

config_manager = ConfigManager()

# ƒê·ªãnh nghƒ©a kh√≥a v√† k√≠ch th∆∞·ªõc shared memory (ch·ªâ d√πng cho Real-time)
SHM_KEY = 0x1234
SEM_KEY = 0x5678
SHM_SIZE = 176400  # 2 gi√¢y d·ªØ li·ªáu = 176400 bytes = 88200 m·∫´u int16

EXCEED_LIMIT = 1

def gtgram_tf(audio_array, sr, window_time, hop_time, channels, f_min):
    """GPU-accelerated gammatone spectrogram using TensorFlow ops."""
    window_size = int(sr * window_time)
    hop_size = int(sr * hop_time)
    audio = tf.convert_to_tensor(audio_array, dtype=tf.float32)
    stft = tf.signal.stft(
        audio,
        frame_length=window_size,
        frame_step=hop_size,
        window_fn=tf.signal.hann_window,
        pad_end=True,
    )
    magnitude = tf.abs(stft)
    spec_bins = tf.shape(magnitude)[-1]
    weights = tf.signal.linear_to_mel_weight_matrix(
        num_mel_bins=channels,
        num_spectrogram_bins=spec_bins,
        sample_rate=sr,
        lower_edge_hertz=f_min,
        upper_edge_hertz=sr / 2,
        dtype=magnitude.dtype,
    )
    gammatone_spec = tf.matmul(tf.square(magnitude), weights)
    return tf.transpose(gammatone_spec)

log_dir = config_manager.get("REALTIME.LOG_PATH", "./logs")
os.makedirs(log_dir, exist_ok=True)
log_file = os.path.join(log_dir, "processing_time.log")
logging.basicConfig(
    filename=log_file,
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

logger.info("C·∫•u h√¨nh m·∫∑c ƒë·ªãnh:")
logger.info(config_manager.config)

# L·∫•y tham s·ªë c·∫•u h√¨nh t·ª´ config
frame_rate = config_manager.get("PREPROCESS.FRAME_RATE")
window_time = config_manager.get("PREPROCESS.GAMMA.WINDOW_TIME")
hop_time = config_manager.get("PREPROCESS.GAMMA.HOP_TIME")
channels = config_manager.get("PREPROCESS.GAMMA.CHANNELS")
f_min = config_manager.get("PREPROCESS.GAMMA.F_MIN")
model_path = config_manager.get("REALTIME.MODEL_PATH") + "/saved_model/vq_vae"
manual_threshold = config_manager.get("REALTIME.MANUAL_THRESHOLD")
threshold = config_manager.get("REALTIME.THRESHOLD")
MIN = config_manager.get("REALTIME.MIN")
MAX = config_manager.get("REALTIME.MAX")
use_tf_gamma = config_manager.get("PREPROCESS.USE_TF_GTGRAM")

# print(f"model_path: {model_path}")
# print(f"frame_rate: {frame_rate}, window_time: {window_time}, hop_time: {hop_time}, channels: {channels}, f_min: {f_min}")
# print(f"manual_threshold: {manual_threshold}, threshold: {threshold}, MIN: {MIN}, MAX: {MAX}")

# Load model
use_trt = config_manager.get("DEVICE.USE_TENSORRT")
trt_model_path = config_manager.get("REALTIME.TRT_MODEL_PATH")

run_model = None

def _setup_model():
    global run_model
    if use_trt and trt is not None:
        try:
            if trt_model_path and os.path.exists(trt_model_path):
                model = tf.saved_model.load(trt_model_path)
                infer = model.signatures['serving_default']
            else:
                converter = trt.TrtGraphConverterV2(input_saved_model_dir=model_path)
                converter.convert()
                if trt_model_path:
                    converter.save(trt_model_path)
                    model = tf.saved_model.load(trt_model_path)
                else:
                    model = converter.convert()
                infer = model.signatures['serving_default'] if hasattr(model, 'signatures') else model

            def run_trt(a):
                result = infer(tf.convert_to_tensor(a))
                return list(result.values())[0].numpy() if isinstance(result, dict) else result.numpy()

            run_model = run_trt
            return
        except Exception as e:
            logger.error(f"TensorRT conversion failed: {e}. Falling back to TensorFlow model.")

    model = load_model(model_path)
    run_model = lambda a: model.predict(a, verbose=0)

_setup_model()
# model.summary()

shm = None
semaphore = None

def cleanup():
    """D·ªçn d·∫πp shared memory v√† semaphore khi tho√°t."""
    global shm, semaphore
    if shm:
        try:
            shm.detach()
            logger.info("Shared memory detached.")
        except Exception as e:
            logger.error(f"Failed to detach shared memory: {e}")
            
def signal_handler(signum, frame):
    """X·ª≠ l√Ω t√≠n hi·ªáu (SIGINT, SIGTERM)."""
    logger.info(f"Signal {signum} received. Exiting...")
    cleanup()
    sys.exit(0)

def wait_for_shared_memory():
    """Ch·ªù shared memory v√† semaphore c√≥ s·∫µn (ch·ªâ d√πng cho real-time)."""
    global shm, semaphore
    while True:
        try:
            shm = sysv_ipc.SharedMemory(SHM_KEY)
            logger.info("Shared memory connected.")
            break
        except sysv_ipc.ExistentialError:
            logger.info("Shared memory kh√¥ng t·ªìn t·∫°i. ƒêang ch·ªù...")
            time.sleep(1)

    while True:
        try:
            semaphore = sysv_ipc.Semaphore(SEM_KEY)
            logger.info("Semaphore connected.")
            break
        except sysv_ipc.ExistentialError:
            logger.info("Semaphore kh√¥ng t·ªìn t·∫°i. ƒêang ch·ªù...")
            time.sleep(1)

def predict_mse(audio_array):
    # D·ª± ƒëo√°n MSE t·ª´ audio array
    if use_tf_gamma and tf is not None:
        gtg = gtgram_tf(audio_array, frame_rate, window_time, hop_time, channels, f_min).numpy()
    else:
        gtg = gtgram.gtgram(audio_array, frame_rate, window_time, hop_time, channels, f_min)
    a = np.flipud(20 * np.log10(gtg + 1e-10))  # Tr√°nh log(0)
    a = np.clip((a-MIN)/(MAX-MIN), a_min=0, a_max=1)
    # print(f"Spectrogram shape: {a.shape}")
    a = np.reshape(a, (1 ,a.shape[0], a.shape[1], 1))
    # print(f"Reshaped Spectrogram shape: {a.shape}")

    if a.shape != (1, 32, 32, 1):
        logger.error(f"Input shape kh√¥ng h·ª£p l·ªá: {a.shape}")
        return None
 
    pred = run_model(a)
    return np.mean((a - pred) ** 2)  

def process_realtime():
    """X·ª≠ l√Ω Real-time: ƒê·ªçc shared memory v√† inference m·ªói 2 gi√¢y."""
    cycle_duration = 2.0  # ƒê·∫£m b·∫£o ƒë√∫ng chu k·ª≥ 2 gi√¢y
    last_read_time = time.time()

    while True:
        cycle_start = time.time()

        # ƒê·ª£i ƒë√∫ng chu k·ª≥ 2 gi√¢y k·ªÉ t·ª´ l·∫ßn ƒë·ªçc tr∆∞·ªõc
        if cycle_start - last_read_time < cycle_duration:
            time.sleep(cycle_duration - (cycle_start - last_read_time))
            continue

        last_read_time = cycle_start  # C·∫≠p nh·∫≠t th·ªùi ƒëi·ªÉm ƒë·ªçc m·ªõi nh·∫•t

        try:
            semaphore.acquire()
            raw_data = bytearray(shm.read(SHM_SIZE))
            semaphore.release()
        except sysv_ipc.BusyError:            
            logger.error("Semaphore is busy. Skipping this cycle.")
            continue

        if len(raw_data) != SHM_SIZE:
            logger.error(f"‚ö†Ô∏è Warning: Expected {SHM_SIZE} bytes but got {len(raw_data)} bytes!")
            
            continue

        start_time = time.time()
        audio_array = np.frombuffer(raw_data, dtype=np.int16)
        # print(f"Real-time - Mean: {np.mean(audio_array)}, Std: {np.std(audio_array)}")
        # print(f"First 5 samples: {audio_array[:5]}")

        # print(f"Sample Rate: {sr}")
        # print(f"Audio Data Shape: {audio_array.shape}")
        # print(f"Max Value: {np.max(audio_array)}, Min Value: {np.min(audio_array)}")
        # print(f"Dtype: {audio_array.dtype}")
        # read_time = time.strftime('%H:%M:%S')
        # print(f"üîÑ Shared memory read at {read_time} - {len(audio_array)} samples, First 10 bit {audio_array[:30]}")

        mse = predict_mse(audio_array)
        if mse is None:
            continue

        # Ki·ªÉm tra anomaly
        if mse > manual_threshold:
            logger.info("Anomaly detected!")
            print("Anomaly detected!", flush=True)
        # print(f"Predict Result: {mse}", flush=True)
        print(mse, flush=True)

        # ƒê·∫£m b·∫£o ƒë·ªçc ƒë√∫ng m·ªói 2 gi√¢y
        elapsed = time.time() - cycle_start
        if elapsed < cycle_duration:
            time.sleep(cycle_duration - elapsed)

        end_time = time.time()
        logger.info(f"Processing time: {end_time - start_time} seconds and Pred: {mse}")
        #print(f"Processing time: {end_time - start_time} seconds and Pred: {mse}")

def process_folder(folder_path):
    """
    X·ª≠ l√Ω √¢m thanh t·ª´ c√°c file WAV trong th∆∞ m·ª•c.
    """
    exceed_count = 0

    wav_files = [f for f in os.listdir(folder_path) if f.lower().endswith(".wav")]
    wav_files.sort()  # Sort to ensure order
    # print(f"Files: {wav_files}")

    for wav_file in wav_files:
        start_time = time.time()
        file_path = os.path.join(folder_path, wav_file)
        # print(f"\n=== ƒêang x·ª≠ l√Ω file: {file_path} ===")

        with wave.open(file_path, 'rb') as wav_file_obj:
            # L·∫•y th√¥ng tin file WAV
            num_channels = wav_file_obj.getnchannels()
            sample_width = wav_file_obj.getsampwidth()
            frame_rate = wav_file_obj.getframerate()
            num_frames = wav_file_obj.getnframes()

            # print(f"File: {wav_file}")
            # print(f"Sample Rate: {frame_rate}")
            # print(f"Channels: {num_channels}")
            # print(f"Sample Width: {sample_width}")
            # print(f"Num Frames: {num_frames}")        

            # ƒê·ªçc d·ªØ li·ªáu √¢m thanh t·ª´ file
            audio_data = wav_file_obj.readframes(num_frames)
            audio_array = np.frombuffer(audio_data, dtype=np.int16)

            # T√≠nh MSE
            mse = predict_mse(audio_array)
            if mse is None:
                continue

            # Ki·ªÉm tra anomaly
            if mse > manual_threshold:
                exceed_count += 1
            else:
                exceed_count = 0

            if exceed_count > EXCEED_LIMIT:
                print("Anomaly detected!", flush=True)
                exceed_count = 0  # reset
            print(mse, flush=True)

            end_time = time.time()
            logger.info(f"Processing time for {wav_file}: {end_time - start_time} seconds and Pred: {mse}")

    logger.info(f"Done!! Total files processed: {len(wav_files)}")        

def main():
    """H√†m ch√≠nh: Ch·ªâ t·ªëi ∆∞u ph·∫ßn Real-time, gi·ªØ nguy√™n ch·∫ø ƒë·ªô ƒë·ªçc file t·ª´ folder."""
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    import_file = config_manager.get("REALTIME.IMPORT_FILE")  # True = Folder Mode, False = Real-time Mode
    logger.info(f"IMPORT_FILE: {import_file}")

    if not import_file:
        logger.info("Ch·∫ø ƒë·ªô Real-time")
        wait_for_shared_memory()
        process_realtime()
    else:
        folder_path = config_manager.get("REALTIME.FOLDER_PATH")
        logger.info(f"Ch·∫ø ƒë·ªô Folder, x·ª≠ l√Ω th∆∞ m·ª•c: {folder_path}")
        process_folder(folder_path)  # Gi·ªØ nguy√™n kh√¥ng thay ƒë·ªïi

if __name__ == "__main__":
    main()
